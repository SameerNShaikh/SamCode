# -*- coding: utf-8 -*-
"""MLCA1_BayesianRidge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NUND3w8v8RnrF5MMTr9Hq2-szda5tVV8

#Bayesian Ridge regressor

"""

############################################ Start of Un-optimized Bayesian Ridge regressor #####################################

import numpy as np
import pandas as pd
import plotly.graph_objs as go
import plotly.figure_factory as ff
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import BayesianRidge
from sklearn.feature_selection import RFE
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score

dataset = pd.read_csv("LifeExpectancy.csv")
#pd.set_option('display.max_columns', None)
#print(dataset.head())
#print(dataset.shape)
#print(dataset.info())
#print(dataset.describe())

dataset.Status = dataset.Status.astype('category').cat.codes

dataset.replace(" ", np.nan, inplace = True)

"""check_missing = dataset.isnull()
#print(check_missing)
for column in check_missing.columns.values.tolist():
  print(column)
  print(check_missing[column].value_counts())
  print("")"""


# Replacing NaN values with the 0
dataset["Life expectancy"].replace(np.nan, 0, inplace=True)

dataset["Adult Mortality"].replace(np.nan, 0, inplace=True)

dataset["infant deaths"].replace(np.nan, 0, inplace=True)

dataset["Alcohol"].replace(np.nan, 0, inplace=True)

dataset["percentage expenditure"].replace(np.nan, 0, inplace=True)

dataset["Hepatitis B"].replace(np.nan, 0, inplace=True)

dataset["BMI"].replace(np.nan, 0, inplace=True)

dataset["Polio"].replace(np.nan, 0, inplace=True)

dataset["Total expenditure"].replace(np.nan, 0, inplace=True)

dataset["Diphtheria"].replace(np.nan, 0, inplace=True)

dataset["HIV/AIDS"].replace(np.nan, 0, inplace=True)

dataset["GDP"].replace(np.nan, 0, inplace=True)

dataset["Population"].replace(np.nan, 0, inplace=True)

dataset["thinness  1-19 years"].replace(np.nan, 0, inplace=True)

dataset["thinness 5-9 years"].replace(np.nan, 0, inplace=True)

dataset["Income composition of resources"].replace(np.nan, 0, inplace=True)

dataset["Schooling"].replace(np.nan, 0, inplace=True)

x = dataset.drop(['Country', 'Status','Life expectancy'], axis = 1)
y = dataset['Life expectancy']

brr = BayesianRidge()
brr.fit(x, y)

print("Score: ", brr.score(x, y))

yPred = brr.predict(x)
print("Prediction: ", yPred)

############################################ End of Un-optimized Bayesian Ridge regressor #####################################


############################################ Start of Optimized Bayesian Ridge regressor ######################################


dataset = pd.read_csv("/content/LifeExpectancy.csv")
#pd.set_option('display.max_columns', None)
#print(dataset.head())
#print(dataset.shape)
#print(dataset.info())
#print(dataset.describe())

dataset.Status = dataset.Status.astype('category').cat.codes

dataset.replace(" ", np.nan, inplace = True)

"""check_missing = dataset.isnull()
#print(check_missing)
for column in check_missing.columns.values.tolist():
  print(column)
  print(check_missing[column].value_counts())
  print("")"""


#Replacing NaN values with the mean of that column
avg_Le = dataset["Life expectancy"].mean(axis=0)
dataset["Life expectancy"].replace(np.nan, avg_Le, inplace=True)

avg_Am = dataset["Adult Mortality"].mean(axis=0)
dataset["Adult Mortality"].replace(np.nan, avg_Am, inplace=True)

avg_Id = dataset["infant deaths"].mean(axis=0)
dataset["infant deaths"].replace(np.nan, avg_Id, inplace=True)

avg_Alc = dataset["Alcohol"].mean(axis=0)
dataset["Alcohol"].replace(np.nan, avg_Alc, inplace=True)

avg_Pe = dataset["percentage expenditure"].mean(axis=0)
dataset["percentage expenditure"].replace(np.nan, avg_Pe, inplace=True)

avg_Hb = dataset["Hepatitis B"].mean(axis=0)
dataset["Hepatitis B"].replace(np.nan, avg_Hb, inplace=True)

avg_Bmi = dataset["BMI"].mean(axis=0)
dataset["BMI"].replace(np.nan, avg_Bmi, inplace=True)

avg_Po = dataset["Polio"].mean(axis=0)
dataset["Polio"].replace(np.nan, avg_Po, inplace=True)

avg_Te = dataset["Total expenditure"].mean(axis=0)
dataset["Total expenditure"].replace(np.nan, avg_Te, inplace=True)

avg_Dp = dataset["Diphtheria"].mean(axis=0)
dataset["Diphtheria"].replace(np.nan, avg_Dp, inplace=True)

avg_Ha = dataset["HIV/AIDS"].mean(axis=0)
dataset["HIV/AIDS"].replace(np.nan, avg_Ha, inplace=True)

avg_Gd = dataset["GDP"].mean(axis=0)
dataset["GDP"].replace(np.nan, avg_Gd, inplace=True)

avg_Pop = dataset["Population"].mean(axis=0)
dataset["Population"].replace(np.nan, avg_Pop, inplace=True)

avg_Th1 = dataset["thinness  1-19 years"].mean(axis=0)
dataset["thinness  1-19 years"].replace(np.nan, avg_Th1, inplace=True)

avg_Th2 = dataset["thinness 5-9 years"].mean(axis=0)
dataset["thinness 5-9 years"].replace(np.nan, avg_Th2, inplace=True)

avg_Ic = dataset["Income composition of resources"].mean(axis=0)
dataset["Income composition of resources"].replace(np.nan, avg_Ic, inplace=True)

avg_Sch = dataset["Schooling"].mean(axis=0)
dataset["Schooling"].replace(np.nan, avg_Sch, inplace=True)

#checking correlation and plotting a heatmap
corrs = dataset.corr()
figure = ff.create_annotated_heatmap(
    z=corrs.values,
    x=list(corrs.columns),
    y=list(corrs.index),
    annotation_text=corrs.round(2).values,
    showscale=True)
figure.show()

x = dataset.drop(['Country','Life expectancy', 'Income composition of resources','infant deaths','percentage expenditure','thinness 5-9 years'], axis = 1)
y = dataset['Life expectancy']

#Performing scaling
feature_scaler = StandardScaler()
X_scaled = feature_scaler.fit_transform(x)

xTrain, xTest, yTrain, yTest = train_test_split(X_scaled, y, test_size = 0.3, random_state = 42)

brr = BayesianRidge()
brr.fit(xTrain, yTrain)

print("Score: ", brr.score(xTest, yTest))

yPred = brr.predict(xTest)
print("Prediction: ", yPred)

# creating a cross-validation scheme
folds = KFold(n_splits = 5, shuffle = True, random_state = 100)

# specifying range of hyperparameters to tune
hyper_params = [{'n_features_to_select': list(range(1, 17))}]

brr.fit(xTrain, yTrain)
rfe = RFE(brr)             

#calling GridSearchCV for cross validation
gd_sr = GridSearchCV(estimator = rfe, param_grid = hyper_params, scoring= 'r2', cv = folds, verbose = 1, return_train_score=True)      

# fitting the model
gd_sr.fit(xTrain, yTrain)
crossval_results = pd.DataFrame(gd_sr.cv_results_)
best_result = gd_sr.best_score_
print("best result: ", best_result)
print("Score: ", brr.score(xTest, yTest))
r2 = r2_score(yTest, yPred)
print("r2 Score: ", r2)
print("Prediction: ", yPred)

# plotting the graph for cv results
plt.figure(figsize=(18,10))

plt.plot(crossval_results["param_n_features_to_select"], crossval_results["mean_test_score"])
plt.plot(crossval_results["param_n_features_to_select"], crossval_results["mean_train_score"])
plt.xlabel('number of features')
plt.ylabel('r-squared')
plt.title("Optimal Number of Features")
plt.legend(['test score', 'train score'], loc='lower right')

############################################ End of Optimized Bayesian Ridge regressor ######################################